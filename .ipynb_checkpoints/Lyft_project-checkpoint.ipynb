{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liberaries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import datetime\n",
    "import cpi\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING!\n",
    "\n",
    "`cpi.update()` is a heavy function that updates the entire CPI package and is very bloaty and unnecessary! \n",
    "\n",
    "**Uncomment and run if absolutely needed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpi.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qrznzr7vcG1HMd7ae2E7'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import API key\n",
    "from SECRET_KEY import quandel_key\n",
    "quandel_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ************** START OF THE RESEARCH*********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Course of Action:\n",
    "\n",
    "1) Create an index for companies that could project how lyft should function. \n",
    "\n",
    "2) Create a function to do the these steps to a single stock\n",
    "    - Import first 261 days (1 fiscal year) of stock prices for each stock\n",
    "    - keep the Open, High, Low, Close, Volume, Ex-Dividend for each stock in the dataframe\n",
    "    - Adjust for inflation using easy money\n",
    "    - create a column to isolate the month for seasionality\n",
    "    - number each instance by # of day in the year\n",
    "    - Save to a .csv in the /data directory\n",
    "    \n",
    "3) Create a function to Graph a given dataframe\n",
    "\n",
    "4) Create a fucntion to merge the datasets together. \n",
    "\n",
    "5) Normalize the full DS\n",
    "\n",
    "6) Instaniate a linuar regression model and train it with the overall data\n",
    "\n",
    "7) Use what Lyft stock data we have to predict to test the first year of Lyft IPO\n",
    "\n",
    "8) Make some sexy visuals from the prediction \n",
    "\n",
    "9) Analize the accuracy of the model\n",
    "\n",
    "10) Create alternative indexes and repeat this process for all of them.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to combine multiple indexes\n",
    "def super_index(index_a, index_b):\n",
    "    super_index = index_a\n",
    "    for i in index_b:\n",
    "        super_index.append(i)\n",
    "    return super_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combiend index\n",
    "# cmb_index = super_index(tech_index, transportation_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     my_data_dict = {\"years\": list(),\n",
    "#                     \"months\": list()}\n",
    "    \n",
    "#     for item in df[\"Date\"]:\n",
    "#         my_data_dict[\"years\"].append(item.year)\n",
    "#         my_data_dict[\"months\"].append(item.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map of DJIA and import it into the stock column\n",
    "djia=pd.read_csv('data/djia.csv')\n",
    "djia.columns =['Date', \"DJIA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DJIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>17897.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>17926.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>17908.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>17721.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>17556.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      DJIA\n",
       "0  2016-04-15  17897.46\n",
       "1  2016-04-14  17926.43\n",
       "2  2016-04-13  17908.28\n",
       "3  2016-04-12  17721.25\n",
       "4  2016-04-11  17556.41"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_process_stock(stock): #Stock is a stock code string\n",
    "    \"\"\"Uploads the data from Quandl and runs through the various \n",
    "        processes to get the data we want adjusted for inflation. \n",
    "        once data is processed it saves to a .csv and returns data in a dataframe\n",
    "        if local .csv of stock data exists it returns that data as a dataframe\"\"\"\n",
    "\n",
    "    if os.path.isfile(\"data/\"+stock+\".csv\"):\n",
    "        df= pd.read_csv(\"data/\"+stock+\".csv\")\n",
    "        return df\n",
    "    \n",
    "    df = quandl.get((\"WIKI/\"+stock), api_key=quandel_key)\n",
    "#     - keep the Open, High, Low, Close, Volume, Ex-Dividend for each stock in the dataframe\n",
    "    df = df[['Open','High','Low','Close','Volume','Ex-Dividend']]\n",
    "    #Import first 261 days \n",
    "#     (1 fiscal year) of stock prices for each stock\n",
    "    df = df.iloc[:261]   \n",
    "    #Bring the timeserise index into the datafraem\n",
    "    df=df.reset_index()\n",
    "    #Add day and month numbers to time serise\n",
    "    df['d_number'] = range(1, len(df)+1)\n",
    "#   create a column to isolate the month for seasionality\n",
    "    df['Year'], df['Month'] = 0,0\n",
    "    my_data_dict = {\"years\": list(),\n",
    "                    \"months\": list()}\n",
    "    \n",
    "    for item in df[\"Date\"]:\n",
    "        my_data_dict[\"years\"].append(int(item.year))\n",
    "        my_data_dict[\"months\"].append(int(item.month))\n",
    "\n",
    "    df[\"Year\"] = my_data_dict[\"years\"]\n",
    "    df[\"Month\"] = my_data_dict[\"months\"]\n",
    "\n",
    "    #improt DJIA data:\n",
    "    df.Date = df.Date.dt.strftime('%Y-%m-%d')\n",
    "    df = df.merge(djia, how='outer', on='Date')\n",
    "    df = df.iloc[:261] \n",
    "\n",
    "    # Adjust for inflation using Consumer Price Index\n",
    "    inflated_closing_vals = list()\n",
    "    inflated_high_vals = list()\n",
    "    inflated_low_vals= list()\n",
    "    \n",
    "    for index, year in enumerate(df[\"Year\"].astype(int)):\n",
    "        inflated_closing_vals.append(round(cpi.inflate(df[\"Close\"].iloc[index], year, to=2018), 2))\n",
    "        inflated_high_vals.append(round(cpi.inflate(df[\"High\"].iloc[index], year, to=2018), 2))\n",
    "        inflated_low_vals.append(round(cpi.inflate(df[\"Low\"].iloc[index], year, to=2018), 2))\n",
    "        \n",
    "    df[\"inflated_close\"] = inflated_closing_vals\n",
    "    df[\"inflated_high\"] = inflated_high_vals\n",
    "    df[\"inflated_low\"] = inflated_low_vals\n",
    "\n",
    "    #convert stuff to int\n",
    "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "    df[\"Month\"] = df[\"Month\"].astype(int)\n",
    "    df[\"d_number\"] = df[\"d_number\"].astype(int)\n",
    "    df[\"Volume\"] = df[\"Volume\"].astype(int)\n",
    "\n",
    "    # rearange table\n",
    "    df=df[[\"Date\",\"d_number\", \"Month\", \"Year\", \"Volume\", \"DJIA\", \n",
    "           \"inflated_high\", \"inflated_low\",\"inflated_close\"]]\n",
    "#     - Save to a .csv in the /data directory\n",
    "    df.to_csv(\"data/\"+stock+\".csv\")\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock_list(stock_list):\n",
    "    \"\"\"This function takes a list of stocks, runs the process function on them and \n",
    "        returns one large datafraame of concantonated data from all stocks\"\"\"\n",
    "    #instantiate datframe\n",
    "    df1 = import_process_stock(stock_list[0])\n",
    "    #run a loop on all other dataframes processing and combineing them to the originonal datafame. \n",
    "    for index in range(1,len(stock_list)-1):\n",
    "        new_df = import_process_stock(stock_list[index])\n",
    "        df1 = pd.concat([df1, new_df])\n",
    "        \n",
    "    return df1\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_df(df):\n",
    "    \"\"\"\"Graphs the closeing prie of a DF\"\"\"\n",
    "    df[\"inflated_close\"].plot()\n",
    "    plt.legend(loc=4)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.show()\n",
    "    \n",
    "    ##WHY THE FUCK IS IT PLOTING THE D_NUMBER INSTED OF DATE? WHAT THE FLYING FUCK!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_stock_csv(stock):\n",
    "    \"\"\"Opens the lyft csv downlaoded from Yahoo stocks\"\"\"\n",
    "    df= pd.read_csv(\"data/\"+stock+\".csv\")\n",
    "    # Make it look like the rest of the stocks\n",
    "#     df=df.reset_index()\n",
    "    #Add day and month numbers to time serise\n",
    "    df['d_number'] = range(1, len(df)+1)\n",
    "#   create a column to isolate the month for seasionality\n",
    "\n",
    "    df['Year'], df['Month'] = 0,0\n",
    "    my_data_dict = {\"years\": list(),\n",
    "                    \"months\": list()}\n",
    "    \n",
    "    for item in df[\"Date\"]:\n",
    "        d_list= item.split(\"-\")\n",
    "        my_data_dict[\"years\"].append(d_list[0])\n",
    "        my_data_dict[\"months\"].append(d_list[1])\n",
    "\n",
    "    df[\"Year\"] = my_data_dict[\"years\"]\n",
    "    df[\"Month\"] = my_data_dict[\"months\"]\n",
    "    \n",
    "\n",
    "    df[\"inflated_high\"]= df[\"High\"]\n",
    "    df[\"inflated_low\"]= df[\"Low\"]\n",
    "    df[\"inflated_close\"]=df[\"Close\"]\n",
    "    #make it like the same\n",
    "    df=df[[\"Date\",\"d_number\", \"Month\", \"Year\", \"Volume\", \"DJIA\", \"inflated_close\"]]\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_stock_predictor(features, df, train_size=0.75):\n",
    "    \"\"\" Runs a Support Vector Machine for Regression on a stock/index. \"\"\"\n",
    "    \n",
    "    # Train the data\n",
    "    X, y = df[features], df[\"inflated_close\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, test_size=1 - train_size)\n",
    "    \n",
    "    # Fit the data\n",
    "    hyper = {\n",
    "        \"kernel\": \"linear\",\n",
    "        \"degree\": 3,\n",
    "        \"C\": 1.0,\n",
    "        \"gamma\": 0.001\n",
    "    }\n",
    "    model_SVR = SVR(kernel=hyper[\"kernel\"])\n",
    "    model_SVR.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model_SVR.predict(X_test)\n",
    "    accuracy = model_SVR.score(X_test, y_test)\n",
    "#     weights, intercept = model_SVR.coef_, model_SVR.intercept_\n",
    "#     RSq, MSE = r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ret_params = {\n",
    "        \"y_pred\": y_pred,\n",
    "        \"accuracy\": accuracy,\n",
    "#         \"weights\": weights,\n",
    "#         \"intercept\": intercept,\n",
    "#         \"RSq\": RSq,\n",
    "#         \"MSE\": MSE\n",
    "    }\n",
    "    \n",
    "    return ret_params, model_SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_stock_predictor(features,  df, train_size=0.75):\n",
    "    \"\"\"Runs a linear regression on a stock or index\"\"\"\n",
    "    \n",
    "    #Train the data\n",
    "    X, y = df[features], df[\"inflated_close\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, test_size=1-train_size)\n",
    "    \n",
    "    #fit the data\n",
    "    model_LinReg = LinearRegression()\n",
    "    model_LinReg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model_LinReg.predict(X_test)\n",
    "    weights, intercept = model_LinReg.coef_, model_LinReg.intercept_\n",
    "    RSq, MSE = r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    ret_params = {\n",
    "        \"y_pred\": y_pred,\n",
    "        \"weights\": weights,\n",
    "        \"intercept\": intercept,\n",
    "        \"RSq\": RSq,\n",
    "        \"MSE\": MSE\n",
    "    }\n",
    "    \n",
    "    return ret_params, model_LinReg, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liner_projector(df, days):\n",
    "    \"\"\"This will project a stock price into the future\"\"\"\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_date(regressor):#Predict Price on Given Date\n",
    "    date = 10\n",
    "    predicted_price =regressor.predict(date)\n",
    "    print(predicted_price[0][0],regressor.coef_[0][0] ,regressor.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = import_process_stock(tech_index[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****WORK SECTION****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_feature = [\"DJIA\"]\n",
    "all_features = [\"DJIA\", \"Volume\", \"Year\", \"Month\"]\n",
    "\n",
    "test_ret = linear_stock_predictor(one_feature,tester )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run LR_model on all tech stocks and than the index to see which is most accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) create an index for tech stocks that might behave like Lyft\n",
    "tech_index = ['TWTR', 'GOOGL', 'FB', 'AMZN', 'SPLK', 'PYPL', 'YHOO']\n",
    "\n",
    "#Create an index for transportation companies:\n",
    "# Picked three top and bottom preforming stocks from DJTransportation index:\n",
    "#  https://www.marketwatch.com/investing/index/djt\n",
    "\n",
    "transportation_index= ['MATX', 'LUV', 'JBLU', 'CAR', 'FDX', 'ALK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.793%\n"
     ]
    }
   ],
   "source": [
    "twtr_df=import_process_stock(tech_index[0])\n",
    "\n",
    "avg_RSq = 0\n",
    "for iteration in range(250):\n",
    "    twtr_params, twtr_model, y_true =linear_stock_predictor(all_features,  twtr_df, train_size=0.75)\n",
    "    avg_RSq += twtr_params['RSq']\n",
    "print(\"{:.3f}%\".format(100 * (avg_RSq / 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.214%\n"
     ]
    }
   ],
   "source": [
    "googl_df=import_process_stock(tech_index[1])\n",
    "\n",
    "avg_RSq = 0\n",
    "for iteration in range(250):\n",
    "    googl_params, googl_model, y_true =linear_stock_predictor(all_features,  googl_df, train_size=0.75)\n",
    "    avg_RSq += googl_params['RSq']\n",
    "print(\"{:.3f}%\".format(100 * (avg_RSq / 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.615%\n"
     ]
    }
   ],
   "source": [
    "fb_df=import_process_stock(tech_index[2])\n",
    "\n",
    "avg_RSq = 0\n",
    "for iteration in range(250):\n",
    "    fb_params, fb_model, y_true =linear_stock_predictor(all_features,  fb_df, train_size=0.75)\n",
    "    avg_RSq += fb_params['RSq']\n",
    "print(\"{:.3f}%\".format(100 * (avg_RSq / 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.263%\n"
     ]
    }
   ],
   "source": [
    "amzn_df=import_process_stock(tech_index[3])\n",
    "\n",
    "avg_RSq = 0\n",
    "for iteration in range(250):\n",
    "    amzn_params, amzn_model, y_true =linear_stock_predictor(all_features,  amzn_df, train_size=0.75)\n",
    "    avg_RSq += amzn_params['RSq']\n",
    "print(\"{:.3f}%\".format(100 * (avg_RSq / 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.231%\n"
     ]
    }
   ],
   "source": [
    "splk_df=import_process_stock(tech_index[4])\n",
    "\n",
    "avg_RSq = 0\n",
    "for iteration in range(250):\n",
    "    splk_params, splk_model, y_true =linear_stock_predictor(all_features,  splk_df, train_size=0.75)\n",
    "    avg_RSq += ppyl_params['RSq']\n",
    "print(\"{:.3f}%\".format(100 * (avg_RSq / 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.335%\n"
     ]
    }
   ],
   "source": [
    "pypl_df=import_process_stock(tech_index[5])\n",
    "\n",
    "avg_RSq = 0\n",
    "for iteration in range(250):\n",
    "    ppyl_params, ppyl_model, y_true =linear_stock_predictor(all_features,  pypl_df, train_size=0.75)\n",
    "    avg_RSq += ppyl_params['RSq']\n",
    "print(\"{:.3f}%\".format(100 * (avg_RSq / 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.779%\n"
     ]
    }
   ],
   "source": [
    "yhoo_df=import_process_stock(tech_index[6])\n",
    "\n",
    "avg_RSq = 0\n",
    "for iteration in range(250):\n",
    "    yhoo_params, yhoo_model, y_true =linear_stock_predictor(all_features,  yhoo_df, train_size=0.75)\n",
    "    avg_RSq += yhoo_params['RSq']\n",
    "print(\"{:.3f}%\".format(100 * (avg_RSq / 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.215662757225472\n"
     ]
    }
   ],
   "source": [
    "# All of the tech index\n",
    "tech_index_df= process_stock_list(tech_index)\n",
    "\n",
    "\n",
    "tech_index_params, tech_index_model =linear_stock_predictor(all_features,  tech_index_df, train_size=0.75)\n",
    "print(tech_index_params['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_ret_all, linreg_model = linear_stock_predictor(all_features,tester )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_ret_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y-line = {:.6f}X1 + {:.6f}X2 + {:.6f}X3 + {:.6f}X4 + {:.2f}\".format(linreg_ret_all[\"weights\"][0],\n",
    "                                                                           linreg_ret_all[\"weights\"][1],\n",
    "                                                                           linreg_ret_all[\"weights\"][2],\n",
    "                                                                           linreg_ret_all[\"weights\"][3], \n",
    "                                                                           linreg_ret_all[\"intercept\"]))\n",
    "\n",
    "print(\"\\nX1: {}\\nX2: {}\\nX3: {}\\nX4: {}\\n\".format(all_features[0],\n",
    "                                                all_features[1],\n",
    "                                                all_features[2],\n",
    "                                                all_features[3]))\n",
    "\n",
    "lookup_year, lookup_month = 2019, 6\n",
    "#            DJIA      Vol         Year         Month\n",
    "new_data = [[17897.46, 12345600.0, lookup_year, lookup_month],\n",
    "            [18550.62, 21156200.0, lookup_year, lookup_month]]\n",
    "linreg_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ester.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyft= open_stock_csv('LYFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_DFF = process_stock_list(tech_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_DFF.to_csv('data/tech_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
